{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Addition_Subtraction_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "            \n",
    "        #print(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+- '\n",
    "ctable = CharacterTable(chars)\n",
    "print(ctable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Data(DIGITS = 3, DATA_SIZE = 50000, MAXLEN):\n",
    "    questions = []\n",
    "    expected = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(questions) < TRAINING_SIZE / 2:    ## the amount of generated data is TRAINING_SIZE\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b, c = f(), f(), f()\n",
    "\n",
    "        if(a+b>=c):   #####\n",
    "            # Skip any addition questions we've already seen\n",
    "            # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "            key = tuple(sorted((a, b, c)))\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            # Pad the data with spaces such that it is always MAXLEN.\n",
    "            q = '{}+{}-{}'.format(a, b, c)    #####\n",
    "            query = q + ' ' * (MAXLEN - len(q))\n",
    "            ans = str(a + b - c)   #####\n",
    "            # Answers can be of maximum size DIGITS + 1.\n",
    "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "            if REVERSE:\n",
    "                # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "                # space used for padding.)\n",
    "                query = query[::-1]\n",
    "            questions.append(query)\n",
    "            expected.append(ans)\n",
    "\n",
    "    while len(questions) >= TRAINING_SIZE / 2 and len(questions) < TRAINING_SIZE:    ## the amount of generated data is TRAINING_SIZE\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b, c = f(), f(), f()\n",
    "\n",
    "        if(a>b):   #####\n",
    "            # Skip any addition questions we've already seen\n",
    "            # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "            key = tuple(sorted((a, b, c)))\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            # Pad the data with spaces such that it is always MAXLEN.\n",
    "            q = '{}-{}+{}'.format(a, b, c)    #####\n",
    "            query = q + ' ' * (MAXLEN - len(q))\n",
    "            ans = str(a - b + c)   #####\n",
    "            # Answers can be of maximum size DIGITS + 1.\n",
    "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "            if REVERSE:\n",
    "                # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "                # space used for padding.)\n",
    "                query = query[::-1]\n",
    "            questions.append(query)\n",
    "            expected.append(ans)\n",
    "    print('Total addition questions:', len(questions))\n",
    "    \n",
    "    return questions, expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorization(questions, expected):\n",
    "    print('Vectorization...')\n",
    "    x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "    for i, sentence in enumerate(questions):\n",
    "        x[i] = ctable.encode(sentence, MAXLEN)\n",
    "    for i, sentence in enumerate(expected):\n",
    "        y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Data and Validation Data\n",
    "* total data = 50000, 45000 for training, 5000 for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, expected = Generate_Data(DIGITS = DIGITS, DATA_SIZE = TRAINING_SIZE, MAXLEN = MAXLEN)\n",
    "x, y = Vectorization(questions, expected)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model(RNN, HIDDEN_SIZE, BATCH_SIZE, LAYERS, MAXLEN, DIGITS, chars):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "    model.add(layers.Dense((DIGITS + 1) * 512))\n",
    "    model.add(layers.Reshape(((DIGITS + 1), 512)))\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(len(chars), activation='softmax')))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Step(model, epoch, REVERSE = True):\n",
    "    for iteration in range(1, epoch):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=1,\n",
    "                  validation_data=(x_val, y_val))\n",
    "        # Select 10 samples from the validation set at random so we can visualize\n",
    "        # errors.\n",
    "        for i in range(10):\n",
    "            ind = np.random.randint(0, len(x_val))\n",
    "            rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "            preds = model.predict_classes(rowx, verbose=0)\n",
    "            q = ctable.decode(rowx[0])\n",
    "            correct = ctable.decode(rowy[0])\n",
    "            guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "            print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "            print('T', correct, end=' ')\n",
    "            if correct == guess:\n",
    "                print(colors.ok + '☑' + colors.close, end=' ')\n",
    "            else:\n",
    "                print(colors.fail + '☒' + colors.close, end=' ')\n",
    "            print(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Matching\n",
    "* training 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 512   #128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "model = Build_Model(RNN = RNN, HIDDEN_SIZE = HIDDEN_SIZE, BATCH_SIZE = BATCH_SIZE, LAYERS = LAYERS, MAXLEN = MAXLEN, DIGITS = DIGITS, chars = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Step(model, epoch = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Testing Data\n",
    "questions_test, expected_test = Generate_Data(DIGITS = DIGITS, DATA_SIZE = 1000, MAXLEN = MAXLEN)\n",
    "x_test, y_test = Vectorization(questions_test, expected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "count_correct = 0\n",
    "preds = model.predict_classes(x_test, verbose=0)\n",
    "print(\"Visualize 10 Data (Total Testing Data = 1000)\")\n",
    "for i in range(1000):\n",
    "    q = ctable.decode(x_test[i])\n",
    "    correct = ctable.decode(y_test[i])\n",
    "    guess = ctable.decode(preds[i], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        count_correct += 1\n",
    "    if i < 10:\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "    \n",
    "print(\"Testing Accuracy : \",(float)(count_correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "### * 利用LSTM做encoder-decoder的seq2seq架構來實現加減混合\n",
    "### * Training data總數為50000筆，45000為training，5000為validation\n",
    "### * Batch size = 128\n",
    "### * RNN hidden layer = 512\n",
    "### * Optimizer使用adam\n",
    "### * Epochs = 300\n",
    "### * Validation result可達99.97%\n",
    "### * Testing data總數為1000筆，Testing accuracy可達 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Discussion\n",
    "* 實驗使用不同的epoch和batch size訓練\n",
    "* 實驗不同位數的數字\n",
    "* 實驗\"more number subtract\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 實驗使用不同的epoch和batch size訓練\n",
    "* with batch = 64, epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 512   #128\n",
    "BATCH_SIZE = 64\n",
    "LAYERS = 1\n",
    "\n",
    "model = Build_Model(RNN = RNN, HIDDEN_SIZE = HIDDEN_SIZE, BATCH_SIZE = BATCH_SIZE, LAYERS = LAYERS, MAXLEN = MAXLEN, DIGITS = DIGITS, chars = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Step(model, epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "count_correct = 0\n",
    "preds = model.predict_classes(x_test, verbose=0)\n",
    "print(\"Visualize 10 Data (Total Testing Data = 1000)\")\n",
    "for i in range(1000):\n",
    "    q = ctable.decode(x_test[i])\n",
    "    correct = ctable.decode(y_test[i])\n",
    "    guess = ctable.decode(preds[i], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        count_correct += 1\n",
    "    if i < 10:\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "    \n",
    "print(\"Testing Accuracy : \",(float)(count_correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 實驗使用不同的epoch和batch size訓練\n",
    "* with batch = 256, epoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 512   #128\n",
    "BATCH_SIZE = 256\n",
    "LAYERS = 1\n",
    "\n",
    "model = Build_Model(RNN = RNN, HIDDEN_SIZE = HIDDEN_SIZE, BATCH_SIZE = BATCH_SIZE, LAYERS = LAYERS, MAXLEN = MAXLEN, DIGITS = DIGITS, chars = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Step(model, epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "count_correct = 0\n",
    "preds = model.predict_classes(x_test, verbose=0)\n",
    "print(\"Visualize 10 Data (Total Testing Data = 1000)\")\n",
    "for i in range(1000):\n",
    "    q = ctable.decode(x_test[i])\n",
    "    correct = ctable.decode(y_test[i])\n",
    "    guess = ctable.decode(preds[i], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        count_correct += 1\n",
    "    if i < 10:\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "    \n",
    "print(\"Testing Accuracy : \",(float)(count_correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 實驗使用不同的epoch和batch size訓練\n",
    "* with batch = 128, epoch = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 512   #128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "model = Build_Model(RNN = RNN, HIDDEN_SIZE = HIDDEN_SIZE, BATCH_SIZE = BATCH_SIZE, LAYERS = LAYERS, MAXLEN = MAXLEN, DIGITS = DIGITS, chars = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Step(model, epoch = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "count_correct = 0\n",
    "preds = model.predict_classes(x_test, verbose=0)\n",
    "print(\"Visualize 10 Data (Total Testing Data = 1000)\")\n",
    "for i in range(1000):\n",
    "    q = ctable.decode(x_test[i])\n",
    "    correct = ctable.decode(y_test[i])\n",
    "    guess = ctable.decode(preds[i], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        count_correct += 1\n",
    "    if i < 10:\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "    \n",
    "print(\"Testing Accuracy : \",(float)(count_correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 實驗不同位數的數字\n",
    "* The digits of input number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different data\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 4\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+- '\n",
    "ctable = CharacterTable(chars)\n",
    "print(ctable)\n",
    "\n",
    "questions, expected = Generate_Data(DIGITS = DIGITS, DATA_SIZE = TRAINING_SIZE, MAXLEN = MAXLEN)\n",
    "x, y = Vectorization(questions, expected)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 512   #128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "model = Build_Model(RNN = RNN, HIDDEN_SIZE = HIDDEN_SIZE, BATCH_SIZE = BATCH_SIZE, LAYERS = LAYERS, MAXLEN = MAXLEN, DIGITS = DIGITS, chars = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Step(model, epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Testing Data\n",
    "questions_test, expected_test = Generate_Data(DIGITS = DIGITS, DATA_SIZE = 1000, MAXLEN = MAXLEN)\n",
    "x_test, y_test = Vectorization(questions_test, expected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "count_correct = 0\n",
    "preds = model.predict_classes(x_test, verbose=0)\n",
    "print(\"Visualize 10 Data (Total Testing Data = 1000)\")\n",
    "for i in range(1000):\n",
    "    q = ctable.decode(x_test[i])\n",
    "    correct = ctable.decode(y_test[i])\n",
    "    guess = ctable.decode(preds[i], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        count_correct += 1\n",
    "    if i < 10:\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "    \n",
    "print(\"Testing Accuracy : \",(float)(count_correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 三個數字相加相減\n",
    "* Add/subtract 3 number (3 digits) together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_OtherData(DIGITS = 3, DATA_SIZE = 50000, MAXLEN):\n",
    "    questions = []\n",
    "    expected = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(questions) < DATA_SIZE / 2:\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b, c = f(), f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        if((a+b)>=c):\n",
    "            key = tuple(sorted((a, b, c)))\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            # Pad the data with spaces such that it is always MAXLEN.\n",
    "            q = '{}+{}-{}'.format(a, b, c)\n",
    "            query = q + ' ' * (MAXLEN - len(q))\n",
    "            ans = str(a + b - c)\n",
    "            # Answers can be of maximum size DIGITS + 1.\n",
    "            ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "            if REVERSE:\n",
    "                # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "                # space used for padding.)\n",
    "                query = query[::-1]\n",
    "            questions.append(query)\n",
    "            expected.append(ans)\n",
    "            \n",
    "    while len(questions) >= TRAINING_SIZE / 2 and len(questions) < TRAINING_SIZE:    ## the amount of generated data is TRAINING_SIZE\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b, c = f(), f(), f()\n",
    "\n",
    "    if(a>b):   #####\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b, c)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = '{}-{}+{}'.format(a, b, c)    #####\n",
    "        query = q + ' ' * (MAXLEN - len(q))\n",
    "        ans = str(a - b + c)   #####\n",
    "        # Answers can be of maximum size DIGITS + 1.\n",
    "        ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "        if REVERSE:\n",
    "            # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "            # space used for padding.)\n",
    "            query = query[::-1]\n",
    "        questions.append(query)\n",
    "        expected.append(ans)\n",
    "    print('Total addition questions:', len(questions))\n",
    "    \n",
    "    return questions, expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate different data\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+- '\n",
    "ctable = CharacterTable(chars)\n",
    "print(ctable)\n",
    "\n",
    "questions, expected = Generate_OtherData(DIGITS = DIGITS, DATA_SIZE = TRAINING_SIZE, MAXLEN = MAXLEN)\n",
    "x, y = Vectorization(questions, expected)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 512   #128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "model = Build_Model(RNN = RNN, HIDDEN_SIZE = HIDDEN_SIZE, BATCH_SIZE = BATCH_SIZE, LAYERS = LAYERS, MAXLEN = MAXLEN, DIGITS = DIGITS, chars = chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Step(model, epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Testing Data\n",
    "questions_test, expected_test = Generate_OtherData(DIGITS = DIGITS, DATA_SIZE = 1000, MAXLEN = MAXLEN)\n",
    "x_test, y_test = Vectorization(questions_test, expected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "count_correct = 0\n",
    "preds = model.predict_classes(x_test, verbose=0)\n",
    "print(\"Visualize 10 Data (Total Testing Data = 1000)\")\n",
    "for i in range(1000):\n",
    "    q = ctable.decode(x_test[i])\n",
    "    correct = ctable.decode(y_test[i])\n",
    "    guess = ctable.decode(preds[i], calc_argmax=False)\n",
    "    if correct == guess:\n",
    "        count_correct += 1\n",
    "    if i < 10:\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)\n",
    "    \n",
    "print(\"Testing Accuracy : \",(float)(count_correct / len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 總結\n",
    "## 在Addition_Subtraction_rnn中採用lstm實現加減混合\n",
    "## 實驗:\n",
    "### 1. 採用四種不同的batch size和訓練epochs (兩個三位數相加相減)\n",
    "###     * [ batch size = 128, epoch = 300 ] : Validation acc = 99.98% / Testing acc (1000 testing data) = 0.99\n",
    "###     * [ batch size = 64,   epoch = 300 ] : Validation acc = 99.98% / Testing acc (1000 testing data) = 1.0\n",
    "###     * [ batch size = 256, epoch = 300 ] : Validation acc = 99.97% / Testing acc (1000 testing data) = 1.0\n",
    "###     * [ batch size = 128, epoch = 150 ] : Validation acc = 99.97% / Testing acc (1000 testing data) = 1.0\n",
    "### 2. 兩個四位數相加相減\n",
    "###     * [ batch size = 128, epoch = 300 ] : Validation acc = 99.58% / Testing acc (1000 testing data) = 0.96\n",
    "### 3. 三個三位數相加相減\n",
    "###     * [ batch size = 128, epoch = 300 ] : Validation acc = 99.24% / Testing acc (1000 testing data) = 0.98 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
